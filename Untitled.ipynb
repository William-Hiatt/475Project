{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe86cbc7",
   "metadata": {},
   "source": [
    "Resources used:\n",
    "https://www.kaggle.com/datasets/tobycrabtree/nfl-scores-and-betting-data/data\n",
    "https://www.kaggle.com/datasets/sampaynedataanalyst/nfl-regular-season-defensive-stats-2004-2022\n",
    "https://www.kaggle.com/datasets/sampaynedataanalyst/nfl-regular-season-offensive-stats-2004-2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67cece31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "!pip install nfl_data_py\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install sportsreference\n",
    "!pip install seaborn\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install xgboost\n",
    "!pip install openpyxl\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff6e4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nfl_data_py as nfl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8951122",
   "metadata": {},
   "source": [
    "# Output Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f81419a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842096b7",
   "metadata": {},
   "source": [
    "# Import all the CSV files used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c8445a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell block takes more time so it's put here to avoid long rung times in case\n",
    "# I add more files\n",
    "years_list = [2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "positions = []\n",
    "\n",
    "# Contains each player and their associated team and some other info\n",
    "season_roster = nfl.import_seasonal_rosters(years_list)\n",
    "\n",
    "# Get's combine details to get more info on players\n",
    "combine_details = nfl.import_combine_data() ## GET COMBINE DATA HERE\n",
    "\n",
    "# Stats for each player\n",
    "player_stats = nfl.import_seasonal_data(years_list)\n",
    "\n",
    "# Imports info about team such as logo and different abbrev\n",
    "team_info = nfl.import_team_desc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f9951",
   "metadata": {},
   "source": [
    "# Get Defensive Player Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2e32fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_roster = season_roster.drop(columns=['depth_chart_position',\n",
    "                                            'jersey_number',\n",
    "                                            'status',\n",
    "                                            'first_name',\n",
    "                                            'last_name',\n",
    "                                            'player_id',\n",
    "                                            'espn_id',\n",
    "                                            'sportradar_id',\n",
    "                                            'yahoo_id',\n",
    "                                            'rotowire_id',\n",
    "                                            'pff_id',\n",
    "                                            'pfr_id',\n",
    "                                            'fantasy_data_id',\n",
    "                                            'sleeper_id',\n",
    "                                            'headshot_url',\n",
    "                                            'ngs_position',\n",
    "                                            'week',\n",
    "                                            'game_type',\n",
    "                                            'status_description_abbr',\n",
    "                                            'football_name',\n",
    "                                            'esb_id',\n",
    "                                            'gsis_it_id',\n",
    "                                            'smart_id',\n",
    "                                            'entry_year',\n",
    "                                            'rookie_year',\n",
    "                                            'draft_club',\n",
    "                                            'draft_number'\n",
    "                                           ])\n",
    "\n",
    "\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'OL'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'QB'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'RB'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'WR'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'K'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'LS'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'P'].index)\n",
    "season_roster = season_roster.drop(season_roster[season_roster['position'] == 'TE'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3451900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful abbreviations and such for each team.\n",
    "nfl_teams = pd.read_csv('nfl_teams.csv')\n",
    "# Same as above with some edits to match another DF\n",
    "nfl_team_names = pd.read_csv('nfl_team_names.csv')\n",
    "\n",
    "# NFL offensive stats and records\n",
    "nfl_offensive = pd.read_excel('NFLRegSeasonOffenseStats.xlsx')\n",
    "\n",
    "# NFL Defensive stats and records\n",
    "nfl_defensive = pd.read_excel('NFLRegSeasonDefenseStats.xlsx')\n",
    "\n",
    "# Defensive Stats From 2016-2022\n",
    "# These are no longer in use and just read the CSV that was created from it\n",
    "# d2016 = pd.read_excel('2016_player_stats.xlsx')\n",
    "# d2017 = pd.read_excel('2017_player_stats.xlsx')\n",
    "# d2018 = pd.read_excel('2018_player_stats.xlsx')\n",
    "# d2019 = pd.read_excel('2019_player_stats.xlsx')\n",
    "# d2020 = pd.read_excel('2020_player_stats.xlsx')\n",
    "# d2021 = pd.read_excel('2021_player_stats.xlsx')\n",
    "# d2022 = pd.read_excel('2022_player_stats.xlsx')\n",
    "\n",
    "# defensive_stats = pd.concat([d2016, d2017, d2018, d2019, d2020, d2021, d2022])\n",
    "# defensive_stats = defensive_stats.fillna(0)\n",
    "# defensive_stats.to_csv('16to22DStats.csv')\n",
    "defensive_stats = pd.read_csv('16to22DStats.csv')\n",
    "\n",
    "d_roster = pd.read_csv('defensive_roster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d26caa",
   "metadata": {},
   "source": [
    "   # Create the master DB for teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "25ff0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two together\n",
    "master_db = pd.merge(nfl_offensive, nfl_defensive, on=['Team', 'Year'])\n",
    "\n",
    "# Drop everything except the desired years\n",
    "master_db = master_db.loc[(master_db['Year'] >= years_list[0])\n",
    "                         & (master_db['Year'] <= years_list[-1])]\n",
    "\n",
    "# Drop undsesired rows\n",
    "master_db = master_db.drop(columns=['iso_code_x',\n",
    "                                    'iso_code_y',\n",
    "                                    'Conference_x',\n",
    "                                    'Conference_y',\n",
    "                                    'City_x',\n",
    "                                    'City_y',\n",
    "                                    'State_x',\n",
    "                                    'State_y',\n",
    "                                    'Wins_y',\n",
    "                                    'Losses_y',\n",
    "                                    'Ties_y'\n",
    "                                   ])\n",
    "master_db = master_db.rename(columns={'Wins_x': 'Wins',\n",
    "                                      'Losses_x': 'Losses',\n",
    "                                      'Ties_x': 'Ties'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0cf75",
   "metadata": {},
   "source": [
    "# Clean Defensive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa153688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNo longer used as the excel doc has been saved past this point\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'OL'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RG'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RT'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LG'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LT'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LG/RG'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'C'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'G'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'T'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'C'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == '0'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'QB'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RB'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'WR'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'K'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LS'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'P'].index)\\ndefensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'TE'].index)\\n\""
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all offensive players that may have a defensive stat such as a tackle chasing down\n",
    "# an interception or a fumble return\n",
    "'''\n",
    "No longer used as the excel doc has been saved past this point\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'OL'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RG'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RT'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LG'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LT'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LG/RG'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'C'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'G'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'T'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'C'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == '0'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'QB'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'RB'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'WR'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'K'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'LS'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'P'].index)\n",
    "defensive_stats = defensive_stats.drop(defensive_stats[defensive_stats['Pos'] == 'TE'].index)\n",
    "'''\n",
    "\n",
    "# defensive_stats.to_csv('16to22DStats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184f498",
   "metadata": {},
   "source": [
    "# Create the Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2b032276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation_matrix_original(df):\n",
    "    # The highest correlation's\n",
    "    # 1. Passing_TDs 0.568530\n",
    "    # 2. Interceptions Thrown -0.486708\n",
    "    # 3. Pass Defelections 0.468254\n",
    "    # 4. Interceptions 0.437715\n",
    "    # 5. Rushing TDs 0.427232\n",
    "    # 6. Sacks 0.405297\n",
    "    \n",
    "    temp_df = df.drop(columns=\"Team\")\n",
    "    correlation = temp_df.corr(method = 'pearson')\n",
    "    display(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80b5a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation_matrix_defence(df):\n",
    "    # The highest correlation's\n",
    "    # 1. Passing_TDs 0.568530\n",
    "    # 2. Interceptions Thrown -0.486708\n",
    "    # 3. Pass Defelections 0.468254\n",
    "    # 4. Interceptions 0.437715\n",
    "    # 5. Rushing TDs 0.427232\n",
    "    # 6. Sacks 0.405297\n",
    "    \n",
    "    temp_df = df.drop(columns=['season_x', 'player_name', 'Tm', 'Pos', 'season_y', 'pos', 'school'])\n",
    "    correlation = temp_df.corr(method = 'pearson')\n",
    "    display(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280133f",
   "metadata": {},
   "source": [
    "# Clean combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2163905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  olb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ilb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
      "C:\\Users\\seaha\\AppData\\Local\\Temp\\ipykernel_25880\\3919438436.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = combine_details\n",
    "df.to_csv(\"combinedata.csv\")\n",
    "df = df.drop(columns=[\n",
    "    'draft_year',\n",
    "    'draft_team',\n",
    "    'draft_round',\n",
    "    'draft_ovr',\n",
    "    'pfr_id',\n",
    "    'cfb_id'\n",
    "])\n",
    "\n",
    "# Updates height to inches and an int\n",
    "for index, row in df.iterrows():\n",
    "    if row['ht']:\n",
    "        ht_list = row['ht'].split('-')\n",
    "        ht_inch = (int(ht_list[0]) * 12) + int(ht_list[1])\n",
    "        df.at[index,'ht'] = ht_inch\n",
    "\n",
    "\n",
    "\n",
    "de_combine_data = df[df['pos'] == 'DE']\n",
    "dt_combine_data = df[df['pos'] == 'DT']\n",
    "olb_combine_data = df[df['pos'] == 'OLB']\n",
    "ilb_combine_data = df[df['pos'] == 'ILB']\n",
    "cb_combine_data = df[df['pos'] == 'CB']\n",
    "s_combine_data = df[df['pos'] == 'S']\n",
    "\n",
    "de_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "de_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "de_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "de_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "de_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "de_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "de_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "de_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "dt_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "dt_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "dt_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "dt_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "dt_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "dt_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "dt_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "dt_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "olb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "olb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "olb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "olb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "olb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "olb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "olb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "olb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "ilb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "ilb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "ilb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "ilb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "ilb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "ilb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "ilb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "ilb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "cb_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "cb_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "cb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "cb_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "cb_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "cb_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "cb_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "cb_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "s_combine_data['ht'].fillna(int(df['ht'].mean()), inplace=True)\n",
    "s_combine_data['wt'].fillna(int(df['wt'].mean()), inplace=True)\n",
    "s_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "s_combine_data['forty'].fillna(int(df['forty'].mean()), inplace=True)\n",
    "s_combine_data['bench'].fillna(int(df['bench'].mean()), inplace=True)\n",
    "s_combine_data['broad_jump'].fillna(int(df['broad_jump'].mean()), inplace=True)\n",
    "s_combine_data['cone'].fillna(int(df['cone'].mean()), inplace=True)\n",
    "s_combine_data['shuttle'].fillna(int(df['shuttle'].mean()), inplace=True)\n",
    "\n",
    "# Combine them all back together\n",
    "combine_data = pd.concat([s_combine_data, cb_combine_data, \n",
    "                           ilb_combine_data, olb_combine_data, \n",
    "                           dt_combine_data, de_combine_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8160c39",
   "metadata": {},
   "source": [
    "# Getting team averages at every position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "361443a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm</th>\n",
       "      <th>season</th>\n",
       "      <th>Wins</th>\n",
       "      <th>team_name_short</th>\n",
       "      <th>team_name</th>\n",
       "      <th>DEfortyAvg</th>\n",
       "      <th>DEhtAvg</th>\n",
       "      <th>DEwtAvg</th>\n",
       "      <th>DEverticalAvg</th>\n",
       "      <th>DTwtAvg</th>\n",
       "      <th>DTbroadAvg</th>\n",
       "      <th>DTverticalAvg</th>\n",
       "      <th>DTfortyAvg</th>\n",
       "      <th>OLBwtAvg</th>\n",
       "      <th>OLBbroadAvg</th>\n",
       "      <th>OLBhtAvg</th>\n",
       "      <th>OLBverticalAvg</th>\n",
       "      <th>CBverticalAvg</th>\n",
       "      <th>CBbroadAvg</th>\n",
       "      <th>SverticalAvg</th>\n",
       "      <th>SwtAvg</th>\n",
       "      <th>SconeAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>306.200000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.068000</td>\n",
       "      <td>249.666667</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>73.666667</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>121.857143</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>6.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>306.666667</td>\n",
       "      <td>106.833333</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>5.098333</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>259.500000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>307.400000</td>\n",
       "      <td>105.400000</td>\n",
       "      <td>29.625000</td>\n",
       "      <td>5.162000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>119.200000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.816667</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>261.333333</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>107.200000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.142000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>120.200000</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>196.250000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2020</td>\n",
       "      <td>13</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>257.500000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>5.163333</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.714286</td>\n",
       "      <td>120.428571</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>197.666667</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.842500</td>\n",
       "      <td>75.250000</td>\n",
       "      <td>267.250000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>302.200000</td>\n",
       "      <td>108.200000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>5.098000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>7.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>302.750000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>240.500000</td>\n",
       "      <td>121.750000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.773333</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>271.333333</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>302.333333</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>5.103333</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>33.625000</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>7.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.822500</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>271.750000</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>239.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>200.800000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.705000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>5.040000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>119.333333</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>7.034000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tm  season  Wins team_name_short team_name  DEfortyAvg  \\\n",
       "0       Buffalo Bills    2016     7           Bills       BUF    4.700000   \n",
       "1       Buffalo Bills    2017     6           Bills       BUF    4.700000   \n",
       "2       Buffalo Bills    2018     6           Bills       BUF    4.780000   \n",
       "3       Buffalo Bills    2019    10           Bills       BUF    4.816667   \n",
       "4       Buffalo Bills    2020    13           Bills       BUF    4.875000   \n",
       "..                ...     ...   ...             ...       ...         ...   \n",
       "184  Seattle Seahawks    2017     9        Seahawks       SEA    4.842500   \n",
       "185  Seattle Seahawks    2018    10        Seahawks       SEA    4.860000   \n",
       "186  Seattle Seahawks    2019    11        Seahawks       SEA    4.773333   \n",
       "187  Seattle Seahawks    2020    12        Seahawks       SEA    4.822500   \n",
       "188  Seattle Seahawks    2021     7        Seahawks       SEA    4.705000   \n",
       "\n",
       "       DEhtAvg     DEwtAvg  DEverticalAvg     DTwtAvg  DTbroadAvg  \\\n",
       "0    75.000000  269.000000      33.000000  306.200000  108.000000   \n",
       "1    75.000000  269.000000      33.000000  306.666667  106.833333   \n",
       "2    76.000000  259.500000      34.250000  307.400000  105.400000   \n",
       "3    75.666667  261.333333      31.666667  308.000000  107.200000   \n",
       "4    76.000000  257.500000      31.000000  307.000000  107.000000   \n",
       "..         ...         ...            ...         ...         ...   \n",
       "184  75.250000  267.250000      34.000000  302.200000  108.200000   \n",
       "185  76.000000  273.000000      34.166667  302.750000  105.500000   \n",
       "186  76.666667  271.333333      33.833333  302.333333  109.000000   \n",
       "187  76.500000  271.750000      32.875000  307.000000  104.000000   \n",
       "188  77.500000  276.000000      32.000000  297.666667  111.000000   \n",
       "\n",
       "     DTverticalAvg  DTfortyAvg    OLBwtAvg  OLBbroadAvg   OLBhtAvg  \\\n",
       "0        28.000000    5.068000  249.666667   116.000000  73.666667   \n",
       "1        27.800000    5.098333  239.000000   122.000000  73.000000   \n",
       "2        29.625000    5.162000  239.000000   122.000000  73.000000   \n",
       "3        30.000000    5.142000  239.000000   122.000000  73.000000   \n",
       "4        30.166667    5.163333  237.000000   122.250000  72.750000   \n",
       "..             ...         ...         ...          ...        ...   \n",
       "184      28.900000    5.098000  249.000000   119.666667  76.000000   \n",
       "185      28.750000    5.130000  240.500000   121.750000  75.500000   \n",
       "186      32.333333    5.103333  236.500000   118.500000  74.000000   \n",
       "187      31.000000    5.210000  239.333333   120.000000  74.333333   \n",
       "188      33.833333    5.040000  245.000000   121.000000  75.000000   \n",
       "\n",
       "     OLBverticalAvg  CBverticalAvg  CBbroadAvg  SverticalAvg      SwtAvg  \\\n",
       "0         34.000000      36.916667  121.857143     37.500000  206.000000   \n",
       "1         34.750000      32.800000  117.000000     40.500000  213.000000   \n",
       "2         34.750000      33.100000  119.200000     37.000000  201.000000   \n",
       "3         34.750000      34.200000  120.200000     35.666667  196.250000   \n",
       "4         34.000000      33.714286  120.428571     35.666667  197.666667   \n",
       "..              ...            ...         ...           ...         ...   \n",
       "184       32.333333      38.000000  123.500000     32.250000  217.500000   \n",
       "185       33.833333      38.000000  123.000000     32.666667  202.000000   \n",
       "186       32.000000      37.000000  122.500000     33.625000  199.500000   \n",
       "187       32.750000      36.833333  119.666667     34.300000  200.800000   \n",
       "188       37.000000      36.000000  119.333333     34.200000  211.000000   \n",
       "\n",
       "     SconeAvg  \n",
       "0    6.720000  \n",
       "1    7.000000  \n",
       "2    7.000000  \n",
       "3    7.000000  \n",
       "4    7.000000  \n",
       "..        ...  \n",
       "184  7.235000  \n",
       "185  6.993333  \n",
       "186  7.080000  \n",
       "187  7.000000  \n",
       "188  7.034000  \n",
       "\n",
       "[189 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm</th>\n",
       "      <th>season</th>\n",
       "      <th>Wins</th>\n",
       "      <th>team_name_short</th>\n",
       "      <th>team_name</th>\n",
       "      <th>DEfortyAvg</th>\n",
       "      <th>DEhtAvg</th>\n",
       "      <th>DEwtAvg</th>\n",
       "      <th>DEverticalAvg</th>\n",
       "      <th>DTwtAvg</th>\n",
       "      <th>DTbroadAvg</th>\n",
       "      <th>DTverticalAvg</th>\n",
       "      <th>DTfortyAvg</th>\n",
       "      <th>OLBwtAvg</th>\n",
       "      <th>OLBbroadAvg</th>\n",
       "      <th>OLBhtAvg</th>\n",
       "      <th>OLBverticalAvg</th>\n",
       "      <th>CBverticalAvg</th>\n",
       "      <th>CBbroadAvg</th>\n",
       "      <th>SverticalAvg</th>\n",
       "      <th>SwtAvg</th>\n",
       "      <th>SconeAvg</th>\n",
       "      <th>ILBverticalAvg</th>\n",
       "      <th>ILBbroadAvg</th>\n",
       "      <th>ILBwtAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>306.200000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.068000</td>\n",
       "      <td>249.666667</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>73.666667</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>121.857143</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>306.666667</td>\n",
       "      <td>106.833333</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>5.098333</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>239.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>2020</td>\n",
       "      <td>13</td>\n",
       "      <td>Bills</td>\n",
       "      <td>BUF</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>257.500000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>5.163333</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>33.714286</td>\n",
       "      <td>120.428571</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>197.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.616493</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>243.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>77.333333</td>\n",
       "      <td>275.666667</td>\n",
       "      <td>32.833333</td>\n",
       "      <td>313.750000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>5.027500</td>\n",
       "      <td>240.600000</td>\n",
       "      <td>123.200000</td>\n",
       "      <td>74.400000</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>34.125000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>208.666667</td>\n",
       "      <td>7.143333</td>\n",
       "      <td>33.616493</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>4.745000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>30.125000</td>\n",
       "      <td>5.085000</td>\n",
       "      <td>235.666667</td>\n",
       "      <td>122.333333</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>122.600000</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>210.250000</td>\n",
       "      <td>7.080000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>106.333333</td>\n",
       "      <td>243.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.842500</td>\n",
       "      <td>75.250000</td>\n",
       "      <td>267.250000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>302.200000</td>\n",
       "      <td>108.200000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>5.098000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>7.235000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>34.166667</td>\n",
       "      <td>302.750000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>240.500000</td>\n",
       "      <td>121.750000</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.993333</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.773333</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>271.333333</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>302.333333</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>5.103333</td>\n",
       "      <td>236.500000</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>33.625000</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>7.080000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.822500</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>271.750000</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>239.333333</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>200.800000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Seattle Seahawks</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>Seahawks</td>\n",
       "      <td>SEA</td>\n",
       "      <td>4.705000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>297.666667</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>33.833333</td>\n",
       "      <td>5.040000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>119.333333</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>7.034000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tm  season  Wins team_name_short team_name  DEfortyAvg  \\\n",
       "0       Buffalo Bills    2016     7           Bills       BUF    4.700000   \n",
       "1       Buffalo Bills    2017     6           Bills       BUF    4.700000   \n",
       "2       Buffalo Bills    2020    13           Bills       BUF    4.875000   \n",
       "3      Miami Dolphins    2016    10        Dolphins       MIA    4.710000   \n",
       "4      Miami Dolphins    2017     6        Dolphins       MIA    4.745000   \n",
       "..                ...     ...   ...             ...       ...         ...   \n",
       "131  Seattle Seahawks    2017     9        Seahawks       SEA    4.842500   \n",
       "132  Seattle Seahawks    2018    10        Seahawks       SEA    4.860000   \n",
       "133  Seattle Seahawks    2019    11        Seahawks       SEA    4.773333   \n",
       "134  Seattle Seahawks    2020    12        Seahawks       SEA    4.822500   \n",
       "135  Seattle Seahawks    2021     7        Seahawks       SEA    4.705000   \n",
       "\n",
       "       DEhtAvg     DEwtAvg  DEverticalAvg     DTwtAvg  DTbroadAvg  \\\n",
       "0    75.000000  269.000000      33.000000  306.200000  108.000000   \n",
       "1    75.000000  269.000000      33.000000  306.666667  106.833333   \n",
       "2    76.000000  257.500000      31.000000  307.000000  107.000000   \n",
       "3    77.333333  275.666667      32.833333  313.750000  104.250000   \n",
       "4    75.500000  256.000000      32.250000  310.000000  104.500000   \n",
       "..         ...         ...            ...         ...         ...   \n",
       "131  75.250000  267.250000      34.000000  302.200000  108.200000   \n",
       "132  76.000000  273.000000      34.166667  302.750000  105.500000   \n",
       "133  76.666667  271.333333      33.833333  302.333333  109.000000   \n",
       "134  76.500000  271.750000      32.875000  307.000000  104.000000   \n",
       "135  77.500000  276.000000      32.000000  297.666667  111.000000   \n",
       "\n",
       "     DTverticalAvg  DTfortyAvg    OLBwtAvg  OLBbroadAvg   OLBhtAvg  \\\n",
       "0        28.000000    5.068000  249.666667   116.000000  73.666667   \n",
       "1        27.800000    5.098333  239.000000   122.000000  73.000000   \n",
       "2        30.166667    5.163333  237.000000   122.250000  72.750000   \n",
       "3        30.500000    5.027500  240.600000   123.200000  74.400000   \n",
       "4        30.125000    5.085000  235.666667   122.333333  73.333333   \n",
       "..             ...         ...         ...          ...        ...   \n",
       "131      28.900000    5.098000  249.000000   119.666667  76.000000   \n",
       "132      28.750000    5.130000  240.500000   121.750000  75.500000   \n",
       "133      32.333333    5.103333  236.500000   118.500000  74.000000   \n",
       "134      31.000000    5.210000  239.333333   120.000000  74.333333   \n",
       "135      33.833333    5.040000  245.000000   121.000000  75.000000   \n",
       "\n",
       "     OLBverticalAvg  CBverticalAvg  CBbroadAvg  SverticalAvg      SwtAvg  \\\n",
       "0         34.000000      36.916667  121.857143     37.500000  206.000000   \n",
       "1         34.750000      32.800000  117.000000     40.500000  213.000000   \n",
       "2         34.000000      33.714286  120.428571     35.666667  197.666667   \n",
       "3         39.166667      34.125000  125.500000     39.500000  208.666667   \n",
       "4         40.250000      32.700000  122.600000     39.750000  210.250000   \n",
       "..              ...            ...         ...           ...         ...   \n",
       "131       32.333333      38.000000  123.500000     32.250000  217.500000   \n",
       "132       33.833333      38.000000  123.000000     32.666667  202.000000   \n",
       "133       32.000000      37.000000  122.500000     33.625000  199.500000   \n",
       "134       32.750000      36.833333  119.666667     34.300000  200.800000   \n",
       "135       37.000000      36.000000  119.333333     34.200000  211.000000   \n",
       "\n",
       "     SconeAvg  ILBverticalAvg  ILBbroadAvg    ILBwtAvg  \n",
       "0    6.720000       31.000000   113.500000  250.000000  \n",
       "1    7.000000       33.250000   118.500000  239.500000  \n",
       "2    7.000000       33.616493   113.500000  243.500000  \n",
       "3    7.143333       33.616493   114.000000  242.000000  \n",
       "4    7.080000       37.000000   106.333333  243.333333  \n",
       "..        ...             ...          ...         ...  \n",
       "131  7.235000       28.000000   109.000000  235.000000  \n",
       "132  6.993333       39.500000   127.000000  239.000000  \n",
       "133  7.080000       36.000000   118.000000  242.000000  \n",
       "134  7.000000       32.500000   109.000000  245.000000  \n",
       "135  7.034000       32.500000   109.000000  245.000000  \n",
       "\n",
       "[136 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge the defenders stats with the combine stats\n",
    "# need to keep this one as is for matrix\n",
    "defensive_roster = pd.merge(defensive_stats, combine_data, on=['player_name'])\n",
    "\n",
    "# d_roster was saved from defensive roster above and some changes were made manually\n",
    "de_roster = d_roster[d_roster['pos'] == 'DE']\n",
    "dt_roster = d_roster[d_roster['pos'] == 'DT']\n",
    "ilb_roster = d_roster[d_roster['pos'] == 'ILB']\n",
    "olb_roster = d_roster[d_roster['pos'] == 'OLB']\n",
    "cb_roster = d_roster[d_roster['pos'] == 'CB']\n",
    "s_roster = d_roster[d_roster['pos'] == 'S']\n",
    "\n",
    "# What averages we need for each team at each position\n",
    "# DE's = HT, WT, Vertical, forty\n",
    "# DT's WT, broad, vertical, forty\n",
    "# ILB's - vertical, broad, weight\n",
    "# OLBs = weight, broad, ht, vertical\n",
    "# CB's - vertical, broad\n",
    "# S's = vertical, cone, wt\n",
    "\n",
    "# Get the season averages for each team at each position group\n",
    "de = de_roster.groupby(['season', 'Tm'], as_index=False)[['forty', 'ht', 'wt', 'vertical']].mean()\n",
    "dt = dt_roster.groupby(['season', 'Tm'], as_index=False)[['wt', 'broad_jump', 'vertical', 'forty']].mean()\n",
    "ilb = ilb_roster.groupby(['season', 'Tm'], as_index=False)[['vertical', 'broad_jump', 'wt']].mean()\n",
    "olb = olb_roster.groupby(['season', 'Tm'], as_index=False)[['wt', 'broad_jump', 'ht', 'vertical']].mean()\n",
    "cb = cb_roster.groupby(['season', 'Tm'], as_index=False)[['vertical', 'broad_jump']].mean()\n",
    "s = s_roster.groupby(['season', 'Tm'], as_index=False)[['vertical', 'wt', 'cone']].mean()\n",
    "\n",
    "# Fill na with average of column\n",
    "de = de.fillna(de.mean(numeric_only=True))\n",
    "dt = dt.fillna(dt.mean(numeric_only=True))\n",
    "ilb = ilb.fillna(ilb.mean(numeric_only=True))\n",
    "olb = olb.fillna(olb.mean(numeric_only=True))\n",
    "cb = cb.fillna(cb.mean(numeric_only=True))\n",
    "s = s.fillna(s.mean(numeric_only=True))\n",
    "\n",
    "# Rename all the columns before putting into one db\n",
    "de.rename(columns={'forty': 'DEfortyAvg', 'ht': 'DEhtAvg', \n",
    "                   'wt': 'DEwtAvg', 'vertical': 'DEverticalAvg'}, inplace=True)\n",
    "\n",
    "dt.rename(columns={'forty': 'DTfortyAvg', 'broad_jump': 'DTbroadAvg', \n",
    "                   'wt': 'DTwtAvg', 'vertical': 'DTverticalAvg'}, inplace=True)\n",
    "\n",
    "ilb.rename(columns={'broad_jump': 'ILBbroadAvg','wt': 'ILBwtAvg',\n",
    "                    'vertical': 'ILBverticalAvg'}, inplace=True)\n",
    "\n",
    "olb.rename(columns={'ht': 'OLBhtAvg', 'broad_jump': 'OLBbroadAvg', \n",
    "                   'wt': 'OLBwtAvg', 'vertical': 'OLBverticalAvg'}, inplace=True)\n",
    "\n",
    "cb.rename(columns={'broad_jump': 'CBbroadAvg', 'vertical': 'CBverticalAvg'}, inplace=True)\n",
    "\n",
    "s.rename(columns={'cone': 'SconeAvg', 'wt': 'SwtAvg',\n",
    "                  'vertical': 'SverticalAvg'}, inplace=True)\n",
    "\n",
    "# Merge into a single DB doing three different DB's\n",
    "merged_all = pd.merge(de, dt, on=['season', 'Tm'])\n",
    "merged_all = pd.merge(merged_all, olb, on=['season', 'Tm'])\n",
    "merged_all = pd.merge(merged_all, cb, on=['season', 'Tm'])\n",
    "merged_all = pd.merge(merged_all, s, on=['season', 'Tm'])\n",
    "merged_noilb = merged_all\n",
    "merged_all = pd.merge(merged_all, ilb, on=['season', 'Tm'])\n",
    "merged_all.rename(columns={'Tm': 'team_name'}, inplace=True)\n",
    "merged_noilb.rename(columns={'Tm': 'team_name'}, inplace=True)\n",
    "\n",
    "\n",
    "# Setting up the team wins for each year. Have to mess around with some of the data so\n",
    "# that each DB has the same naming conventions\n",
    "master_db_basic = master_db[['Team', 'Year', 'Wins']].copy()\n",
    "master_db_basic.rename(columns={'Team': 'Tm', 'Year': 'season'}, inplace=True)\n",
    "master_db_basic = pd.merge(master_db_basic, nfl_team_names, on=['Tm'])\n",
    "merged_all = pd.merge(master_db_basic, merged_all, on=['season', 'team_name'])\n",
    "merged_noilb = pd.merge(master_db_basic, merged_noilb, on=['season', 'team_name'])\n",
    "\n",
    "display(merged_noilb)\n",
    "display(merged_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce988891",
   "metadata": {},
   "source": [
    "# Print out matrix at positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f6a7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_matrix(defensive_roster):\n",
    "    de_roster = defensive_roster[defensive_roster['pos'] == 'DE']\n",
    "    dt_roster = defensive_roster[defensive_roster['pos'] == 'DT']\n",
    "    ilb_roster = defensive_roster[defensive_roster['pos'] == 'ILB']\n",
    "    olb_roster = defensive_roster[defensive_roster['pos'] == 'OLB']\n",
    "    cb_roster = defensive_roster[defensive_roster['pos'] == 'CB']\n",
    "    s_roster = defensive_roster[defensive_roster['pos'] == 'S']\n",
    "    \n",
    "    print(\"DE's\")\n",
    "    print_correlation_matrix_defence(de_roster)\n",
    "    # Ints leaders - no correlation worth highlighting\n",
    "    # PD's = HT = 0.214029, WT = 0.179563\n",
    "    # Sacks = forty = -0.16631, vertical = 0.164293, and broad jump = 0.144067\n",
    "    # QB hits = forty = -0.130258, vertical = 0.116204, broad_jump = 0.114900\n",
    "\n",
    "    print(\"DT's\")\n",
    "    print_correlation_matrix_defence(dt_roster)\n",
    "    # Ints leaders - None\n",
    "    # PD's = None\n",
    "    # Sacks = wt -0.212267, 40 = -0.125331,bench = 0.116742, vertical = 0.120845, broad = 0.194133, cone = -0.152739\n",
    "    # QB hits = wt = -0.241188, forty = -0.120472, bench = 0.118849, vertical = 0.143933, broad = 0.219948, 0.163284\n",
    "\n",
    "    print(\"ILB's\")\n",
    "    print_correlation_matrix_defence(ilb_roster)\n",
    "    # Ints leaders - None\n",
    "    # PD's = vertical = 0.188513, broad = 0.169417\n",
    "    # Sacks = weight = 0.137233, vertical = 0.146358, \n",
    "    # QB hits = weight = 0.171089, vertical = 0.200448, broad = 0.171032\n",
    "\n",
    "    print(\"OLB's\")\n",
    "    print_correlation_matrix_defence(olb_roster)\n",
    "    # Ints leaders - weight -0.214119, bench -109554\n",
    "    # PD's = weight -0.265915, broad jump = 0.22174\n",
    "    # Sacks = weight =  0.29339, ht = 0.224814, vertical = 0.251377, broad = 0.238754\n",
    "    # QB hits = weight = 0.317846, height = 0.225654, vertical = 0.252409, broad_jump = 0.21810\n",
    "\n",
    "    print(\"CB's\")\n",
    "    print_correlation_matrix_defence(cb_roster)\n",
    "    # Ints leaders - none\n",
    "    # PD's = vertical = 0.128207\n",
    "    # Sacks = vertical = -0.122768, broad_jump = -0.101390\n",
    "    # QB hits = none\n",
    "\n",
    "\n",
    "    print(\"S's\")\n",
    "    print_correlation_matrix_defence(s_roster)\n",
    "    # Ints leaders = vertical = 0.106236, cone = -0.174591\n",
    "    # PD's = none\n",
    "    # Sacks = wt = 0.113393\n",
    "    # QB hits = wt = 0.134692"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87146b6e",
   "metadata": {},
   "source": [
    "# Print final DF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df_matrix(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca57243",
   "metadata": {},
   "source": [
    "# Put into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a30ba1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_csv(df, file_name):\n",
    "    df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128422c0",
   "metadata": {},
   "source": [
    "# Most everything runs through here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2c234d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation\n",
    "#print_correlation_matrix_original(master_db)\n",
    "#position_matrix(defensive_roster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a4a0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts stuff into csv's for easier viewing.\n",
    "#seasonal_roster.to_csv('seasonal_roster.csv')\n",
    "\n",
    "#win_totals.to_csv('win_totals.csv')\n",
    "\n",
    "#player_stats.to_csv('player_stats.csv')\n",
    "\n",
    "#wins.to_csv('wins.csv')\n",
    "\n",
    "#master_db.to_csv('test2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I have since found datasets that contain the wins/losses and this is no longer needed.\n",
    "\n",
    "def get_team_wins(from_date, to_date):\n",
    "    from_date = from_date\n",
    "    to_date = to_date\n",
    "    # Data starting in 1966 of every matchup of every week. Used to get team wins.\n",
    "    team_season_wins = pd.read_csv('spreadspoke_scores.csv')\n",
    "    \n",
    "    # Select our date ranges here\n",
    "    team_season_wins = team_season_wins.loc[(team_season_wins['schedule_season'] >= from_date) \n",
    "                                            & (team_season_wins['schedule_season'] <= to_date)]\n",
    "    # Select only regular season games\n",
    "    team_season_wins = team_season_wins.loc[team_season_wins['schedule_playoff'] != True]\n",
    "    \n",
    "    # Keep some data for weather in case I need it later\n",
    "    team_season_wins_with_weather = team_season_wins.drop(columns = \n",
    "                                             ['schedule_date',\n",
    "                                              'stadium_neutral',\n",
    "                                              'stadium',\n",
    "                                              'over_under_line',\n",
    "                                              'spread_favorite',\n",
    "                                              'team_favorite_id'])\n",
    "\n",
    "    # Drop irrelivent data\n",
    "    team_season_wins = team_season_wins.drop(columns = \n",
    "                                             ['schedule_date',\n",
    "                                              'stadium_neutral',\n",
    "                                              'schedule_playoff',\n",
    "                                              'stadium',\n",
    "                                              'over_under_line',\n",
    "                                              'spread_favorite',\n",
    "                                              'team_favorite_id',\n",
    "                                              'weather_temperature',\n",
    "                                              'weather_wind_mph',\n",
    "                                              'weather_humidity',\n",
    "                                              'weather_detail'])\n",
    "    # Here we create our new dataframe that will have rows\n",
    "    # of each team and their record. Will be used later to\n",
    "    # continue to add averages per team.\n",
    "    new_df = {'Season': [],\n",
    "              'Team': [],\n",
    "              'Wins': [],\n",
    "              'Losses': [],\n",
    "              'Ties': []}\n",
    "    \n",
    "    current_season = \"\"\n",
    "    \n",
    "    for index, row in team_season_wins.iterrows():\n",
    "        home_team = row['team_home']\n",
    "        home_score = row['score_home']\n",
    "\n",
    "        away_team = row['team_away']\n",
    "        away_score = row['score_away']\n",
    "\n",
    "        if row['schedule_season'] == current_season:\n",
    "            # This is used to find out where the start of this season is within the index\n",
    "            season_index = new_df['Season'].index(current_season)\n",
    "            \n",
    "            # This gets our team index within that season\n",
    "            if (home_team in new_df['Team'][season_index:]) & (away_team in new_df['Team'][season_index:]):\n",
    "                home_team_index = new_df['Team'].index(home_team, season_index)\n",
    "                away_team_index = new_df['Team'].index(away_team, season_index)\n",
    "                \n",
    "                # Add win's losses and ties\n",
    "                if home_score > away_score:\n",
    "                    new_df['Wins'][home_team_index] += 1\n",
    "                    new_df['Losses'][away_team_index] += 1\n",
    "                elif home_score < away_score:\n",
    "                    new_df['Wins'][away_team_index] += 1\n",
    "                    new_df['Losses'][home_team_index] += 1\n",
    "                else:\n",
    "                    # It was a tie\n",
    "                    new_df['Ties'][away_team_index] += 1\n",
    "                    new_df['Ties'][home_team_index] += 1\n",
    "            else:\n",
    "                # The team is not in the dictionary for this season\n",
    "                # Put them in with 0's for wins and losses\n",
    "                \n",
    "                new_df['Season'].append(current_season)\n",
    "                new_df['Team'].append(home_team)\n",
    "                new_df['Wins'].append(0)\n",
    "                new_df['Losses'].append(0)\n",
    "                new_df['Ties'].append(0)\n",
    "                home_team_index = len(new_df['Ties']) - 1\n",
    "                \n",
    "                new_df['Season'].append(current_season)\n",
    "                new_df['Team'].append(away_team)\n",
    "                new_df['Wins'].append(0)\n",
    "                new_df['Losses'].append(0)\n",
    "                new_df['Ties'].append(0)\n",
    "                away_team_index = len(new_df['Ties']) - 1\n",
    "                \n",
    "                if home_score > away_score:\n",
    "                    new_df['Wins'][home_team_index] += 1\n",
    "                    new_df['Losses'][away_team_index] += 1\n",
    "                elif home_score < away_score:\n",
    "                    new_df['Wins'][away_team_index] += 1\n",
    "                    new_df['Losses'][home_team_index] += 1\n",
    "                else:\n",
    "                    # It was a tie\n",
    "                    new_df['Ties'][away_team_index] += 1\n",
    "                    new_df['Ties'][home_team_index] += 1\n",
    "\n",
    "        else:\n",
    "            # We are at the first game in a new season\n",
    "            current_season = row['schedule_season']\n",
    "                \n",
    "            new_df['Season'].append(current_season)\n",
    "            new_df['Team'].append(home_team)\n",
    "            new_df['Wins'].append(0)\n",
    "            new_df['Losses'].append(0)\n",
    "            new_df['Ties'].append(0)\n",
    "            home_team_index = len(new_df['Ties']) - 1\n",
    "\n",
    "            new_df['Season'].append(current_season)\n",
    "            new_df['Team'].append(away_team)\n",
    "            new_df['Wins'].append(0)\n",
    "            new_df['Losses'].append(0)\n",
    "            new_df['Ties'].append(0)\n",
    "            away_team_index = len(new_df['Ties']) - 1\n",
    "\n",
    "            if home_score > away_score:\n",
    "                new_df['Wins'][home_team_index] += 1\n",
    "                new_df['Losses'][away_team_index] += 1\n",
    "            elif home_score < away_score:\n",
    "                new_df['Wins'][away_team_index] += 1\n",
    "                new_df['Losses'][home_team_index] += 1\n",
    "            else:\n",
    "                # It was a tie\n",
    "                new_df['Ties'][away_team_index] += 1\n",
    "                new_df['Ties'][home_team_index] += 1\n",
    "    \n",
    "    return_df = pd.DataFrame.from_dict(new_df)\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418442a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a62ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "434hw",
   "language": "python",
   "name": "434hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
